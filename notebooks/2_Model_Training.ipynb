{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "772faff4",
   "metadata": {},
   "source": [
    "PHASE THREE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca79e7ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install xgboost lightgbm catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e347404",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import time\n",
    "import joblib\n",
    "\n",
    "# Metrics\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, \n",
    "    f1_score, \n",
    "    precision_score, \n",
    "    recall_score, \n",
    "    roc_auc_score, \n",
    "    classification_report, \n",
    "    confusion_matrix\n",
    ")\n",
    "\n",
    "# Models\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import (\n",
    "    RandomForestClassifier, \n",
    "    ExtraTreesClassifier, \n",
    "    AdaBoostClassifier\n",
    ")\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "# Helper\n",
    "from collections import Counter\n",
    "\n",
    "print(\"All libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a03d49a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the processed data arrays\n",
    "# Load the processed data arrays\n",
    "X_train_resampled = np.load('../data/processed/X_train_resampled.npy', allow_pickle=True).item()\n",
    "y_train_resampled = np.load('../data/processed/y_train_resampled.npy', allow_pickle=True)\n",
    "X_test_processed = np.load('../data/processed/X_test_processed.npy', allow_pickle=True).item()\n",
    "y_test = np.load('../data/processed/y_test.npy', allow_pickle=True)\n",
    "\n",
    "# Note: y_train and y_test don't need .item() because they were simple 1D arrays.\n",
    "\n",
    "# Load the label encoder\n",
    "le = joblib.load('../models/label_encoder.joblib')\n",
    "labels = le.classes_\n",
    "\n",
    "print(\"Data loaded successfully.\")\n",
    "print(f\"X_train_resampled shape: {X_train_resampled.shape}\")\n",
    "print(f\"y_train_resampled shape: {y_train_resampled.shape}\")\n",
    "print(f\"X_test_processed shape: {X_test_processed.shape}\")\n",
    "print(f\"y_test shape: {y_test.shape}\")\n",
    "print(f\"Target labels: {labels}\") # Should be ['Dropout', 'Enrolled', 'Graduate']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6e169aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary of the models we'll test\n",
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=1000, random_state=42),\n",
    "    \"K-Nearest Neighbors\": KNeighborsClassifier(),\n",
    "    \"Decision Tree\": DecisionTreeClassifier(random_state=42),\n",
    "    \"SGD Classifier\": SGDClassifier(loss='log_loss', random_state=42), # 'log_loss' makes it predict probabilities\n",
    "    \"Support Vector Machine\": SVC(probability=True, random_state=42), # probability=True is needed for ROC-AUC\n",
    "    \"Random Forest\": RandomForestClassifier(random_state=42),\n",
    "    \"Extra Trees\": ExtraTreesClassifier(random_state=42),\n",
    "    \"AdaBoost\": AdaBoostClassifier(random_state=42),\n",
    "    \"XGBoost\": XGBClassifier(use_label_encoder=False, eval_metric='mlogloss', random_state=42),\n",
    "    \"LightGBM\": LGBMClassifier(random_state=42),\n",
    "    \"CatBoost\": CatBoostClassifier(verbose=0, random_state=42) # verbose=0 stops it from printing training logs\n",
    "}\n",
    "\n",
    "print(f\"Defined {len(models)} models.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6d343f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_list = []\n",
    "\n",
    "for name, model in models.items():\n",
    "    print(f\"--- Training {name} ---\")\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # 1. Train the model\n",
    "    model.fit(X_train_resampled, y_train_resampled)\n",
    "    \n",
    "    # 2. Get predictions on the TEST set\n",
    "    y_pred = model.predict(X_test_processed)\n",
    "    \n",
    "    # 3. Get probability predictions (for ROC-AUC)\n",
    "    y_proba = model.predict_proba(X_test_processed)\n",
    "    \n",
    "    # 4. Calculate metrics\n",
    "    train_time = time.time() - start_time\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "    precision = precision_score(y_test, y_pred, average='weighted')\n",
    "    recall = recall_score(y_test, y_pred, average='weighted')\n",
    "    \n",
    "    # ROC-AUC for multi-class\n",
    "    roc_auc = roc_auc_score(y_test, y_proba, multi_class='ovr')\n",
    "    \n",
    "    # 5. Store results\n",
    "    results_list.append({\n",
    "        \"Model\": name,\n",
    "        \"F1 (Weighted)\": f1,\n",
    "        \"Accuracy\": accuracy,\n",
    "        \"ROC-AUC (OVR)\": roc_auc,\n",
    "        \"Precision (Weighted)\": precision,\n",
    "        \"Recall (Weighted)\": recall,\n",
    "        \"Train Time (s)\": train_time\n",
    "    })\n",
    "    \n",
    "    print(f\"Finished {name} in {train_time:.2f}s.\\n\")\n",
    "\n",
    "# Note: SVC might take a few minutes. This is normal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c19a8a71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the list of results into a DataFrame\n",
    "results_df = pd.DataFrame(results_list)\n",
    "\n",
    "# Sort by our most important metric, F1 (Weighted)\n",
    "results_df = results_df.sort_values(by=\"F1 (Weighted)\", ascending=False)\n",
    "\n",
    "print(\"--- Model Comparison ---\")\n",
    "display(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08cca7d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the name of the best performing model\n",
    "best_model_name = results_df.iloc[0]['Model']\n",
    "print(f\"--- In-Depth Analysis for Best Model: {best_model_name} ---\")\n",
    "\n",
    "# Get the already-trained model from our dictionary\n",
    "# Note: In a production environment, you would retrain this model on the *full* dataset\n",
    "# or on the full resampled training set. For this project, using the one from\n",
    "# our loop is perfect.\n",
    "final_model = models[best_model_name]\n",
    "\n",
    "# Get its predictions again (or store them from the loop)\n",
    "y_pred_final = final_model.predict(X_test_processed)\n",
    "\n",
    "# 1. Classification Report\n",
    "# This shows precision, recall, and f1-score for EACH class\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred_final, target_names=labels))\n",
    "\n",
    "# 2. Confusion Matrix\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "cm = confusion_matrix(y_test, y_pred_final)\n",
    "plt.figure(figsize=(10, 7))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=labels, yticklabels=labels)\n",
    "plt.title(f'Confusion Matrix for {best_model_name}')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a983d8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the best model to the 'models' folder\n",
    "model_save_path = f\"../models/best_model.joblib\"\n",
    "joblib.dump(final_model, model_save_path)\n",
    "\n",
    "print(f\"Best model ({best_model_name}) saved to {model_save_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
